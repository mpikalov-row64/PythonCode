{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2323be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed packages\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import csv\n",
    "from row64tools import ramdb\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ccb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######################################\n",
    "#   STEP 1: CONNECT TO THE DATABASE     #\n",
    "#########################################\n",
    "\n",
    "conn = sqlite3.connect(r\"C:\\Users\\mikha\\Downloads\\DBexampleROW64.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18095cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# tables = [row[0] for row in cursor.fetchall()]\n",
    "# rows = [(\"table_name\", \"column_name\", \"data_type\", \"is_primary_key\")]\n",
    "\n",
    "# for table in tables:\n",
    "#     cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "#     columns = cursor.fetchall()\n",
    "#     for col in columns:\n",
    "#         col_id, name, col_type, not_null, default_val, pk = col\n",
    "#         rows.append((table, name, col_type, \"YES\" if pk else \"NO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19098f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_csv = r\"C:\\Users\\mikha\\kmt_db.csv\"\n",
    "# with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(rows)\n",
    "\n",
    "# conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a77f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################\n",
    "#   STEP 2: DATA TRANSFORMATION  #\n",
    "##################################\n",
    "\n",
    " \n",
    "#Grab the data for from LAPANALYSIS table and merge it with other look up tables. Execute the query\n",
    "lap_analysis_query = \"\"\"\n",
    "SELECT \n",
    "    LAPANALYSIS.LapID,\n",
    "    ANALYSISFORMULATION.Name AS FormulationName,\n",
    "    ANALYSISCHANNEL.Name AS ChannelName,\n",
    "    ANALYSISLOCATION.Name AS LocationName,\n",
    "    ANALYSISCONDITION.Name AS ConditionName,\n",
    "    MIN(LAPANALYSIS.Idx) AS ValueMin,\n",
    "    MAX(LAPANALYSIS.Idx) AS ValueMax,\n",
    "    AVG(LAPANALYSIS.Idx) AS ValueAvg\n",
    "FROM LAPANALYSIS\n",
    "JOIN ANALYSISFORMULATION ON LAPANALYSIS.FormulationID = ANALYSISFORMULATION.ID\n",
    "JOIN ANALYSISCHANNEL ON LAPANALYSIS.ChannelID = ANALYSISCHANNEL.ID\n",
    "JOIN ANALYSISLOCATION ON LAPANALYSIS.LocationID = ANALYSISLOCATION.ID\n",
    "JOIN ANALYSISCONDITION ON LAPANALYSIS.ConditionID = ANALYSISCONDITION.ID\n",
    "\n",
    "\n",
    "GROUP BY LAPANALYSIS.LapID, ANALYSISFORMULATION.Name, ANALYSISCHANNEL.Name\n",
    "\"\"\"\n",
    "\n",
    "lap_analysis_df = pd.read_sql_query(lap_analysis_query, conn)\n",
    "\n",
    "#Grab additional information from other lookup tables needed for the reports and dashboards\n",
    "\n",
    "final_query = \"\"\"\n",
    "SELECT \n",
    "    SEASON.Name AS SeasonName,\n",
    "    EVENT.Name AS EventName,\n",
    "    SESSION.Name AS SessionName,\n",
    "    SESSION.Name || '_' || RUN.Number AS SessionRunNumber,\n",
    "    LAP.LapNumber,\n",
    "    RUN.Number AS RunNumber,\n",
    "    RIDER.Alias AS RiderAlias,\n",
    "    LAP.ID AS LapID\n",
    "FROM LAP\n",
    "JOIN RUN ON LAP.RunID = RUN.ID\n",
    "JOIN SESSION ON RUN.SessionID = SESSION.ID\n",
    "JOIN EVENT ON SESSION.EventID = EVENT.ID\n",
    "JOIN SEASON ON EVENT.SeasonID = SEASON.ID\n",
    "JOIN RIDER ON RUN.RiderID = RIDER.ID\n",
    "\"\"\"\n",
    "meta_df = pd.read_sql_query(final_query, conn)\n",
    "\n",
    "\n",
    "# Merge the two dataframes to get one flat table with all sessions, riders, laps, etc.\n",
    "final_df = meta_df.merge(lap_analysis_df, on=\"LapID\", how=\"inner\")\n",
    "\n",
    "# Pivot the data to set each channel type as a separate column\n",
    "final_pivot = final_df.pivot_table(\n",
    "    index=[\n",
    "        \"SeasonName\", \"EventName\", \"SessionName\", \"SessionRunNumber\",\n",
    "        \"LapNumber\", \"RunNumber\", \"RiderAlias\"\n",
    "    ],\n",
    "    columns=\"ChannelName\",\n",
    "    values=[\"ValueMin\", \"ValueMax\", \"ValueAvg\"]\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "final_pivot.columns = [\n",
    "    f\"{col[1]}_{col[0].replace('Value', '').lower()}\" if col[1] else col[0]\n",
    "    for col in final_pivot.columns\n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "# THIS STEP IS OPTIONAL AND IS DONE SO WE ARE ABLE TO PLOT LOCATIONS ON A MAP # \n",
    "###############################################################################\n",
    "\n",
    "# create a table with track names and geo coordinates\n",
    "coords_map = {\n",
    "    'SEPANG': (2.7608, 101.7381),        # Sepang International Circuit, Malaysia\n",
    "    'DOHA': (25.2843, 51.4410),          # Losail Intl Circuit near Doha, Qatar\n",
    "    'SPIELBERG': (47.2190, 14.7640),     # Red Bull Ring, Spielberg, Austria\n",
    "    'MISANO': (43.9620, 12.6846),        # Misano World Circuit, Italy\n",
    "    'ARGENTINA': (-27.5063, -64.9309),   # Termas de Río Hondo Circuit, Argentina\n",
    "    'AUSTIN': (30.1346, -97.6359),       # Circuit of the Americas, Texas, USA\n",
    "    'JEREZ': (36.7081, -6.0341),         # Circuito de Jerez, Spain\n",
    "    'LEMANS': (47.9565, 0.2249),         # Le Mans, France\n",
    "    'MUGELLO': (43.9970, 11.3710),       # Mugello Circuit, Italy\n",
    "    'BARCELONA': (41.5700, 2.2610),      # Circuit de Barcelona-Catalunya, Spain\n",
    "    'ASSEN': (53.0036, 6.5150),          # TT Circuit Assen, Netherlands\n",
    "    'SACHSENRING': (50.7180, 12.6950),   # Sachsenring, Germany\n",
    "    'BRNO': (49.2020, 16.5650),          # Brno Circuit, Czech Republic\n",
    "    'SILVERSTONE': (52.0733, -1.0140),   # Silverstone Circuit, UK\n",
    "    'ARAGON': (41.0670, -0.2160),        # MotorLand Aragón, Spain\n",
    "    'BURIRAM': (14.9576, 103.0849),      # Chang International Circuit, Thailand\n",
    "    'MOTEGI': (36.5323, 140.2267),       # Twin Ring Motegi, Japan\n",
    "    'PISLAND': (-38.4910, 145.2370),     # Phillip Island Circuit, Australia\n",
    "    'VALENCIA': (39.4910, -0.6340),      # Circuit Ricardo Tormo, Spain\n",
    "    'PORTIMAO': (37.2270, -8.6260),      # Algarve Intl Circuit, Portugal\n",
    "    'MANDALIKA': (-8.8830, 116.3080),    # Mandalika International Street Circuit, Indonesia\n",
    "    'TERMAS': (-27.5063, -64.9309),      # Termas de Río Hondo (same as ARGENTINA)\n",
    "    'BUDDH': (28.3487, 77.5331)          # Buddh International Circuit, India\n",
    "}\n",
    "\n",
    "# merge it with the master table by location name in the EventName column\n",
    "final_pivot[\"location\"] = final_pivot[\"EventName\"].str.split().str[-1]\n",
    "final_pivot[[\"latitude\", \"longitude\"]] = final_pivot[\"location\"].map(coords_map).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfec0a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to upload: name 'paramiko' is not defined\n"
     ]
    }
   ],
   "source": [
    "# ###############################\n",
    "#       STEP 3: CLEAN DATA      #\n",
    "#################################\n",
    "\n",
    "\n",
    "# -------------------------------#\n",
    "#   OPTION 1: Create a csv file  #\n",
    "# -------------------------------#\n",
    "final_pivot.to_csv(r\"C:\\Users\\mikha\\final_pivot_output.csv\", index=False)\n",
    "\n",
    "# ------------------------------------#\n",
    "#   OPTION 1: Upload to ROW64 server  #\n",
    "# ------------------------------------#\n",
    "\n",
    "# Create a file \n",
    "ramdb.save_from_df(lap_analysis_df, r\"C:\\Users\\mikha\\LapAnalysisKTM.ramdb\")\n",
    "\n",
    "localfile = r\"C:\\Users\\mikha\\LapAnalysisKTM.ramdb\"\n",
    "\n",
    "remote_path = \"/var/www/ramdb/live/RAMDB.MikhailData/MikhailData/LapAnalysis.ramdb\"\n",
    "\n",
    "# Ubuntu server credentials\n",
    "hostname = \"192.168.1.20\"   # Replace with your Ubuntu server's local IP\n",
    "port = 22\n",
    "username = \"row64\"   # Ubuntu login username\n",
    "password = \"temp7\"   # Or use SSH key auth\n",
    "\n",
    "# Transmit the data\n",
    "try:\n",
    "    # Connect via SSH\n",
    "    transport = paramiko.Transport((hostname, port))\n",
    "    transport.connect(username=username, password=password)\n",
    "\n",
    "    # Start SFTP session\n",
    "    sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "\n",
    "    # Upload file\n",
    "    sftp.put(localfile, remote_path)\n",
    "    print(f\"✅ File uploaded to {remote_path} on {hostname}\")\n",
    "\n",
    "    # Close connection\n",
    "    sftp.close()\n",
    "    transport.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to upload: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d304b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = r\"C:\\Users\\mikha\\LapAnalysisKTM.ramdb\"\n",
    "dst = r\"\\\\wsl.localhost\\Ubuntu\\var\\www\\ramdb\\loading\\RAMDB.Row64\\Temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d101203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\wsl.localhost\\\\Ubuntu\\\\var\\\\www\\\\ramdb\\\\loading\\\\RAMDB.Row64\\\\Temp\\\\LapAnalysisKTM.ramdb'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(src, dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
